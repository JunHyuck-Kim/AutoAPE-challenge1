{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\n\ntrain_df = pd.read_csv(\"/kaggle/input/cat-in-the-dat/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/cat-in-the-dat/test.csv\")\nsub = pd.read_csv(\"/kaggle/input/cat-in-the-dat/sample_submission.csv\")\n\ntrain = train_df.drop(['target'], axis=1)\ntrain_target = train_df['target'].to_numpy()\n\ntrain = train.drop(['id'], axis=1)\ntest = test_df.drop(['id'],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(train[\"nom_9\"][2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.concat([train, test])\n#data =train.append(test, sort=False)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_cols=[\"bin_0\"]\n\n# Split 2 Letters; This is the only part which is not generic and would actually require data inspection\ndata[\"ord_5a\"]=data[\"ord_5\"].str[0]\ndata[\"ord_5b\"]=data[\"ord_5\"].str[1]\n\ndrop_cols.append(\"ord_5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(drop_cols, axis = 1)\n\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in [\"nom_5\", \"nom_6\", \"nom_7\", \"nom_8\", \"nom_9\"]:\n    train_vals = set(train[col].unique())\n    test_vals = set(test[col].unique())\n    xor_cat_vals=train_vals ^ test_vals # xor ,find elements that is in only 1 side\n    print(list(xor_cat_vals))\n    if xor_cat_vals:\n        data.replace(list(xor_cat_vals), \"ddd\")\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"nom_9\"][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in list(set(data[\"nom_9\"].unique())):\n    if i == 'ddd':\n        print(\"found\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for one hot encoding everything!\n\ncolumns = [i for i in data.columns]\ndummies = pd.get_dummies(data,columns=columns, drop_first=True,sparse=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain = dummies.iloc[:train.shape[0], :]\ntest = dummies.iloc[train.shape[0]:, :]\n\nprint(train)\nprint(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.sparse.to_coo().tocsr()\ntest = test.sparse.to_coo().tocsr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### %%time\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score as auc\nfrom sklearn.linear_model import LogisticRegression\n\n# Model\ndef run_cv_model(train, test, target, model_fn, params={}, eval_fn=None, label='model', split=5):\n    kf = KFold(n_splits=split)\n    fold_splits = kf.split(train, target)\n    cv_scores = []\n    pred_full_test = 0\n    pred_train = np.zeros((train.shape[0]))\n    i = 1\n    for dev_index, val_index in fold_splits:\n        print('Started ' + label + ' fold ' + str(i) + '/', split)\n        dev_X, val_X = train[dev_index], train[val_index]\n        dev_y, val_y = target[dev_index], target[val_index]\n        params2 = params.copy()\n        pred_val_y, pred_test_y = model_fn(dev_X, dev_y, val_X, val_y, test, params2)\n        pred_full_test = pred_full_test + pred_test_y\n        pred_train[val_index] = pred_val_y\n        if eval_fn is not None:\n            cv_score = eval_fn(val_y, pred_val_y)\n            cv_scores.append(cv_score)\n            print(label + ' cv score {}: {}'.format(i, cv_score))\n        i += 1\n    print('{} cv scores : {}'.format(label, cv_scores))\n    print('{} cv mean score : {}'.format(label, np.mean(cv_scores)))\n    pred_full_test = pred_full_test / split\n    results = {'label': label,\n              'train': pred_train, 'test': pred_full_test,\n              'cv': cv_scores}\n    return results\n\n\ndef runLR(train_X, train_y, test_X, test_y, test_X2, params):\n    print('Train LR')\n    model = LogisticRegression(**params)\n    model.fit(train_X, train_y)\n    print('Predict 1/2')\n    pred_test_y = model.predict_proba(test_X)[:, 1]\n    print('Predict 2/2')\n    pred_test_y2 = model.predict_proba(test_X2)[:, 1]\n    return pred_test_y, pred_test_y2\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_params = {'solver': 'lbfgs', 'C': 0.1, 'max_iter': 1000}\nresults = run_cv_model(train, test, train_target, runLR, lr_params, auc, 'lr', split=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_id = sub[\"id\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'id': test_id, 'target': results['test']})\nsubmission.to_csv('submission_kfold_max.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}